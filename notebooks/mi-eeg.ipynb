{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98188,"databundleVersionId":12673416,"sourceType":"competition"},{"sourceId":476134,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":382930,"modelId":402385}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Notebook is my try to detect labels according to MI Signals","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader, random_split\nimport torch.optim as optim\nimport torch\nfrom torch.utils.data import Dataset\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:02:28.128088Z","iopub.execute_input":"2025-07-17T16:02:28.128307Z","iopub.status.idle":"2025-07-17T16:02:35.967310Z","shell.execute_reply.started":"2025-07-17T16:02:28.128290Z","shell.execute_reply":"2025-07-17T16:02:35.966730Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!ls /kaggle/input/mtcaic3\nbase_path = \"/kaggle/input/mtcaic3/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:02:41.672789Z","iopub.execute_input":"2025-07-17T16:02:41.673073Z","iopub.status.idle":"2025-07-17T16:02:41.807239Z","shell.execute_reply.started":"2025-07-17T16:02:41.673052Z","shell.execute_reply":"2025-07-17T16:02:41.806572Z"}},"outputs":[{"name":"stdout","text":"MI\t   sample_submission.csv  test.csv   validation.csv\nREADME.md  SSVEP\t\t  train.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Here I load the data as pandas dataframe to analyze the data and to get the correlation between different features","metadata":{}},{"cell_type":"code","source":"def load_trial_data(row, base_path='.'):\n    id_num = row['id']\n    if id_num <= 4800:\n        dataset = 'train'\n    elif id_num <= 4900:\n        dataset = 'validation'\n    else:\n        dataset = 'test'\n\n    eeg_path = f\"{base_path}/{row['task']}/{dataset}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n    eeg_data = pd.read_csv(eeg_path)\n\n    trial_num = int(row['trial'])\n    samples_per_trial = 1750 if row['task'] == 'SSVEP' else 2250\n    start_idx = (trial_num - 1) * samples_per_trial\n    end_idx = start_idx + samples_per_trial - 1\n    return eeg_data.iloc[start_idx:end_idx + 1]\n\ndef load_all_trials_df(df, base_path, start, end):\n    trials = []\n    for i in range(start, end):\n        row = df.iloc[i]\n        trial_df = load_trial_data(row, base_path)\n        trials.append(trial_df)\n\n    return trials\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:02:45.280261Z","iopub.execute_input":"2025-07-17T16:02:45.280597Z","iopub.status.idle":"2025-07-17T16:02:45.286981Z","shell.execute_reply.started":"2025-07-17T16:02:45.280569Z","shell.execute_reply":"2025-07-17T16:02:45.286363Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\nvalidation_df = pd.read_csv(os.path.join(base_path, 'validation.csv'))\ntest_df = pd.read_csv(os.path.join(base_path, 'test.csv'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:02:46.304427Z","iopub.execute_input":"2025-07-17T16:02:46.305010Z","iopub.status.idle":"2025-07-17T16:02:46.355062Z","shell.execute_reply.started":"2025-07-17T16:02:46.304984Z","shell.execute_reply":"2025-07-17T16:02:46.354352Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_x = load_all_trials_df(train_df, base_path,0,2400)\nval_x = load_all_trials_df(validation_df, base_path,0,50)\ntest_x = load_all_trials_df(test_df, base_path,0,50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Assume train_x is a list of DataFrames\nnum_samples = len(train_x)\ncolumns = train_x[0].columns\n\n# Initialize correlation table with zeros\ncorrelation_table = pd.DataFrame(0.0, index=columns, columns=columns)\n\n# Accumulate correlations\nfor df in train_x:\n    for col1 in columns:\n        for col2 in columns:\n            corr = df[col1].corr(df[col2])\n            if pd.notnull(corr):\n                correlation_table.loc[col1, col2] += corr\n\n# Average over all samples\ncorrelation_table /= num_samples\n\n# Round and print\nprint(correlation_table.round(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T11:02:45.121957Z","iopub.execute_input":"2025-07-17T11:02:45.122559Z","iopub.status.idle":"2025-07-17T11:06:53.161044Z","shell.execute_reply.started":"2025-07-17T11:02:45.122530Z","shell.execute_reply":"2025-07-17T11:06:53.160205Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n  c /= stddev[:, None]\n/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n  c /= stddev[None, :]\n","output_type":"stream"},{"name":"stdout","text":"             Time     FZ     C3     CZ     C4     PZ    PO7     OZ    PO8  \\\nTime        1.000  0.008  0.008 -0.043 -0.075 -0.015 -0.005 -0.002 -0.019   \nFZ          0.008  1.000  0.608  0.759  0.676  0.597  0.384  0.472  0.495   \nC3          0.008  0.608  1.000  0.793  0.729  0.767  0.807  0.820  0.726   \nCZ         -0.043  0.759  0.793  1.000  0.903  0.857  0.673  0.763  0.794   \nC4         -0.075  0.676  0.729  0.903  1.000  0.848  0.678  0.759  0.838   \nPZ         -0.015  0.597  0.767  0.857  0.848  1.000  0.788  0.869  0.900   \nPO7        -0.005  0.384  0.807  0.673  0.678  0.788  1.000  0.894  0.843   \nOZ         -0.002  0.472  0.820  0.763  0.759  0.869  0.894  1.000  0.887   \nPO8        -0.019  0.495  0.726  0.794  0.838  0.900  0.843  0.887  1.000   \nAccX       -0.019  0.003  0.005  0.004  0.006  0.006  0.006  0.005  0.009   \nAccY        0.032  0.004 -0.003 -0.003 -0.002 -0.003 -0.001 -0.003 -0.003   \nAccZ        0.066  0.005 -0.002 -0.005 -0.005 -0.002  0.000 -0.003 -0.005   \nGyro1       0.007  0.003  0.001  0.000 -0.001 -0.003 -0.000 -0.002  0.000   \nGyro2       0.001  0.001  0.000  0.000 -0.001 -0.000  0.001 -0.002 -0.002   \nGyro3       0.007  0.002  0.003  0.003  0.002  0.006  0.006  0.006  0.003   \nBattery    -0.005 -0.000 -0.000  0.000  0.000 -0.000 -0.001 -0.000 -0.000   \nCounter     1.000  0.008  0.008 -0.044 -0.075 -0.015 -0.005 -0.002 -0.019   \nValidation -0.002  0.000  0.001 -0.000 -0.000  0.000  0.000  0.000  0.000   \n\n             AccX   AccY   AccZ  Gyro1  Gyro2  Gyro3  Battery  Counter  \\\nTime       -0.019  0.032  0.066  0.007  0.001  0.007   -0.005    1.000   \nFZ          0.003  0.004  0.005  0.003  0.001  0.002   -0.000    0.008   \nC3          0.005 -0.003 -0.002  0.001  0.000  0.003   -0.000    0.008   \nCZ          0.004 -0.003 -0.005  0.000  0.000  0.003    0.000   -0.044   \nC4          0.006 -0.002 -0.005 -0.001 -0.001  0.002    0.000   -0.075   \nPZ          0.006 -0.003 -0.002 -0.003 -0.000  0.006   -0.000   -0.015   \nPO7         0.006 -0.001  0.000 -0.000  0.001  0.006   -0.001   -0.005   \nOZ          0.005 -0.003 -0.003 -0.002 -0.002  0.006   -0.000   -0.002   \nPO8         0.009 -0.003 -0.005  0.000 -0.002  0.003   -0.000   -0.019   \nAccX        1.000 -0.100  0.002 -0.006  0.055  0.137    0.001   -0.019   \nAccY       -0.100  1.000  0.339 -0.030 -0.043 -0.130    0.001    0.032   \nAccZ        0.002  0.339  1.000 -0.102  0.054  0.071    0.000    0.066   \nGyro1      -0.006 -0.030 -0.102  1.000  0.051 -0.151    0.000    0.007   \nGyro2       0.055 -0.043  0.054  0.051  1.000  0.157    0.000    0.001   \nGyro3       0.137 -0.130  0.071 -0.151  0.157  1.000   -0.000    0.007   \nBattery     0.001  0.001  0.000  0.000  0.000 -0.000    0.040   -0.005   \nCounter    -0.019  0.032  0.066  0.007  0.001  0.007   -0.005    1.000   \nValidation -0.001 -0.001  0.000  0.000 -0.000  0.000    0.000    0.002   \n\n            Validation  \nTime            -0.002  \nFZ               0.000  \nC3               0.001  \nCZ              -0.000  \nC4              -0.000  \nPZ               0.000  \nPO7              0.000  \nOZ               0.000  \nPO8              0.000  \nAccX            -0.001  \nAccY            -0.001  \nAccZ             0.000  \nGyro1            0.000  \nGyro2           -0.000  \nGyro3            0.000  \nBattery          0.000  \nCounter          0.002  \nValidation       0.200  \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# --- 3. Your data loading functions ---\n\ndef load_trial_data(row, base_path='.'):\n    id_num = row['id']\n    if id_num <= 4800:\n        dataset = 'train'\n    elif id_num <= 4900:\n        dataset = 'validation'\n    else:\n        dataset = 'test'\n\n    eeg_path = f\"{base_path}/{row['task']}/{dataset}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n    eeg_data = pd.read_csv(eeg_path)\n\n    trial_num = int(row['trial'])\n    samples_per_trial = 1750 if row['task'] == 'SSVEP' else 2250\n    start_idx = (trial_num - 1) * samples_per_trial\n    end_idx = start_idx + samples_per_trial - 1\n    return eeg_data.iloc[start_idx:end_idx + 1]\n\ndef load_all_trials(df, base_path, channels, start, end):\n    trials = []\n    for i in range(start, end):\n        row = df.iloc[i]\n        trial_df = load_trial_data(row, base_path)[channels].to_numpy()\n        trials.append(trial_df)\n\n    trials = np.stack(trials)\n    return trials\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:03:10.190539Z","iopub.execute_input":"2025-07-17T16:03:10.191264Z","iopub.status.idle":"2025-07-17T16:03:10.196833Z","shell.execute_reply.started":"2025-07-17T16:03:10.191242Z","shell.execute_reply":"2025-07-17T16:03:10.196176Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### The Chosen features according to the correlation table","metadata":{}},{"cell_type":"code","source":"MI_channels = ['C3', 'FZ', 'PO8','Time','AccX' ,  'AccY' ,  'AccZ' , 'Gyro1'  ,'Gyro2'  ,'Gyro3']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:03:11.097578Z","iopub.execute_input":"2025-07-17T16:03:11.098260Z","iopub.status.idle":"2025-07-17T16:03:11.101922Z","shell.execute_reply.started":"2025-07-17T16:03:11.098235Z","shell.execute_reply":"2025-07-17T16:03:11.101340Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Loading the data as numpy arrays","metadata":{}},{"cell_type":"code","source":"train_x = load_all_trials(train_df, base_path, MI_channels,0,2400)\nval_x = load_all_trials(validation_df, base_path, MI_channels,0,50)\ntest_x = load_all_trials(test_df, base_path, MI_channels,0,50)\n\n# Since load_all_trials now returns a list, you can check the number of trials loaded\nprint(\"Number of trials in train_x:\", len(train_x))\nprint(\"Number of trials in val_x:\", len(val_x))\nprint(\"Number of trials in test_x:\", len(test_x))\n\n# You can also inspect the shape of the first few trials to see the different lengths\nprint(\"Shape of the first trial in train_x:\", train_x[0].shape)\nprint(\"Shape of the first trial in val_x:\", val_x[0].shape)\nprint(\"Shape of the first trial in test_x:\", test_x[0].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:03:12.459531Z","iopub.execute_input":"2025-07-17T16:03:12.460101Z","iopub.status.idle":"2025-07-17T16:06:38.983331Z","shell.execute_reply.started":"2025-07-17T16:03:12.460078Z","shell.execute_reply":"2025-07-17T16:06:38.982656Z"}},"outputs":[{"name":"stdout","text":"Number of trials in train_x: 2400\nNumber of trials in val_x: 50\nNumber of trials in test_x: 50\nShape of the first trial in train_x: (2250, 10)\nShape of the first trial in val_x: (2250, 10)\nShape of the first trial in test_x: (2250, 10)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_labels=pd.read_csv(base_path+\"train.csv\")\ntrain_labels = train_labels[0:2400]\n\nval_labels=pd.read_csv(base_path+\"validation.csv\")\nval_labels = val_labels[0:50]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:06:38.984426Z","iopub.execute_input":"2025-07-17T16:06:38.984681Z","iopub.status.idle":"2025-07-17T16:06:38.994765Z","shell.execute_reply.started":"2025-07-17T16:06:38.984665Z","shell.execute_reply":"2025-07-17T16:06:38.993935Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_labels = train_labels.iloc[:,-1]\nval_labels = val_labels.iloc[:,-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:06:38.995549Z","iopub.execute_input":"2025-07-17T16:06:38.995815Z","iopub.status.idle":"2025-07-17T16:06:39.004644Z","shell.execute_reply.started":"2025-07-17T16:06:38.995792Z","shell.execute_reply":"2025-07-17T16:06:39.003918Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"label_to_index = {\n    \"Left\": 0,\n    \"Right\": 1,\n}\ntrain_labels = [label_to_index[label] for label in train_labels]\nval_labels = [label_to_index[label] for label in val_labels]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:06:39.006224Z","iopub.execute_input":"2025-07-17T16:06:39.006417Z","iopub.status.idle":"2025-07-17T16:06:39.031147Z","shell.execute_reply.started":"2025-07-17T16:06:39.006403Z","shell.execute_reply":"2025-07-17T16:06:39.030577Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"train_labels = torch.tensor(train_labels, dtype=torch.float32).unsqueeze(1)  # shape: [N, 1]\nval_labels = torch.tensor(val_labels, dtype=torch.float32).unsqueeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:06:39.031872Z","iopub.execute_input":"2025-07-17T16:06:39.032054Z","iopub.status.idle":"2025-07-17T16:06:39.074980Z","shell.execute_reply.started":"2025-07-17T16:06:39.032039Z","shell.execute_reply":"2025-07-17T16:06:39.074490Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_x = torch.from_numpy(train_x)\nval_x = torch.from_numpy(val_x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:06:39.075610Z","iopub.execute_input":"2025-07-17T16:06:39.075769Z","iopub.status.idle":"2025-07-17T16:06:39.082186Z","shell.execute_reply.started":"2025-07-17T16:06:39.075757Z","shell.execute_reply":"2025-07-17T16:06:39.081440Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_x.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T11:13:12.854777Z","iopub.execute_input":"2025-07-17T11:13:12.855020Z","iopub.status.idle":"2025-07-17T11:13:12.860629Z","shell.execute_reply.started":"2025-07-17T11:13:12.855005Z","shell.execute_reply":"2025-07-17T11:13:12.859832Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"torch.Size([2400, 2250, 10])"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### Constructing the model","metadata":{}},{"cell_type":"code","source":"\nclass GRUClassifier(nn.Module):\n    def __init__(self, input_dim=10, hidden_dim=32, num_layers=3, num_classes=1, bidirectional=True):\n        super(GRUClassifier, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n        self.bidirectional = bidirectional\n\n        # BatchNorm on input features (T is time, apply on F across B)\n        self.input_bn = nn.BatchNorm1d(input_dim)\n\n        self.gru = nn.GRU(\n            input_dim,\n            hidden_dim,\n            num_layers,\n            batch_first=True,\n            bidirectional=bidirectional\n        )\n\n        self.output_bn = nn.BatchNorm1d(hidden_dim * (2 if bidirectional else 1))\n        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), num_classes)\n\n    def forward(self, x):\n        # x: [B, T, F] → permute to [B, F, T] for BN1d over F\n        x = self.input_bn(x.permute(0, 2, 1)).permute(0, 2, 1)\n\n        out, h_n = self.gru(x)\n\n        if self.bidirectional:\n            h_n = torch.cat([h_n[-2], h_n[-1]], dim=-1)  # [B, 2H]\n        else:\n            h_n = h_n[-1]  # [B, H]\n\n        h_n = self.output_bn(h_n)  # BN after GRU output\n        logits = self.fc(h_n)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T17:09:43.796012Z","iopub.execute_input":"2025-07-17T17:09:43.796254Z","iopub.status.idle":"2025-07-17T17:09:43.803609Z","shell.execute_reply.started":"2025-07-17T17:09:43.796237Z","shell.execute_reply":"2025-07-17T17:09:43.803060Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class SequenceDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # Return input sequence and label\n        return self.data[idx], self.labels[idx]\n\n\ntrain_dataset = SequenceDataset(train_x, train_labels)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_dataset = SequenceDataset(val_x, val_labels)\nval_loader=DataLoader(val_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:06:54.947329Z","iopub.execute_input":"2025-07-17T16:06:54.947678Z","iopub.status.idle":"2025-07-17T16:06:54.953016Z","shell.execute_reply.started":"2025-07-17T16:06:54.947653Z","shell.execute_reply":"2025-07-17T16:06:54.952497Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model = GRUClassifier()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:45:31.539590Z","iopub.execute_input":"2025-07-17T16:45:31.539836Z","iopub.status.idle":"2025-07-17T16:45:31.546666Z","shell.execute_reply.started":"2025-07-17T16:45:31.539820Z","shell.execute_reply":"2025-07-17T16:45:31.545867Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"def evaluate(model, dataloader, device='cuda'):\n    model.eval()\n    correct = total = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x_batch, y_batch in dataloader:\n            x_batch = x_batch.to(device, torch.float32)\n            y_batch = y_batch.to(device)\n\n            logits = model(x_batch)\n            probs = torch.sigmoid(logits)\n            preds = (probs > 0.5).int()\n\n            correct += (preds == y_batch).sum().item()\n            total += y_batch.size(0)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y_batch.cpu().numpy())\n\n    accuracy = 100.0 * correct / total\n    f1 = f1_score(all_labels, all_preds, average='weighted')  # or 'macro', 'micro' based on need\n\n    return accuracy, f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:07:14.285002Z","iopub.execute_input":"2025-07-17T16:07:14.285263Z","iopub.status.idle":"2025-07-17T16:07:14.290757Z","shell.execute_reply.started":"2025-07-17T16:07:14.285245Z","shell.execute_reply":"2025-07-17T16:07:14.290189Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"max_acc=0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T16:07:14.712285Z","iopub.execute_input":"2025-07-17T16:07:14.712631Z","iopub.status.idle":"2025-07-17T16:07:14.716196Z","shell.execute_reply.started":"2025-07-17T16:07:14.712606Z","shell.execute_reply":"2025-07-17T16:07:14.715491Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"\ndef train(model, train_loader, val_loader, num_epochs=10, lr=1e-3, device='cuda'):\n    global max_acc, max_model\n    model = model.to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n\n        for x_batch, y_batch in train_loader:\n            x_batch = x_batch.to(device, torch.float32)\n            y_batch = y_batch.to(device).float().view(-1, 1)\n              # BCE expects float [B, 1]\n\n            optimizer.zero_grad()\n            logits = model(x_batch)  # [B, 1]\n            loss = criterion(logits, y_batch)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n\n        # Evaluate on train and val\n        #train_acc, train_f1 = evaluate(model, train_loader, device)\n        val_acc, val_f1 = evaluate(model, val_loader, device)\n        if val_acc > max_acc:\n            max_acc = val_acc\n            torch.save(model.state_dict(), \"best_model_mi.pt\")\n\n        print(\n            f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} | \"\n            #f\"Train Acc: {train_acc:.2f}% - F1: {train_f1:.2f} | \"\n            f\"Val Acc: {val_acc:.2f}% - F1: {val_f1:.2f}\"\n        )\n\n\ntrain(model,train_loader,val_loader,100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_best = GRUClassifier()\nmodel_best.load_state_dict(torch.load(\"/kaggle/working/best_model_mi.pt\", map_location=\"cpu\"))\nmodel_best.to(\"cpu\")\nmodel_best.eval()  # optional but recommended during inference\n\ntest = torch.from_numpy(test_x).to(torch.float32)  # ensure float32\ntest = test.to(\"cpu\")  # ensure it's also on CPU\n\nlogits = model_best(test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T17:09:53.060447Z","iopub.execute_input":"2025-07-17T17:09:53.061081Z","iopub.status.idle":"2025-07-17T17:09:55.172499Z","shell.execute_reply.started":"2025-07-17T17:09:53.061059Z","shell.execute_reply":"2025-07-17T17:09:55.171845Z"}},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":"### In this try I succesfully got 68 score in the validation data, I was able before to get 74 accuracy","metadata":{}},{"cell_type":"code","source":"model_best.to(\"cuda\")\nevaluate(model_best, val_loader, \"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T17:09:59.161930Z","iopub.execute_input":"2025-07-17T17:09:59.162209Z","iopub.status.idle":"2025-07-17T17:09:59.204586Z","shell.execute_reply.started":"2025-07-17T17:09:59.162191Z","shell.execute_reply":"2025-07-17T17:09:59.203870Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"(68.0, 0.6810305958132045)"},"metadata":{}}],"execution_count":69}]}